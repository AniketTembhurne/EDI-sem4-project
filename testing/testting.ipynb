{"cells":[{"cell_type":"markdown","metadata":{"id":"ePoUkERg8HpR"},"source":["# `SENTIMENTAL ANALYSIS`"]},{"cell_type":"markdown","metadata":{"id":"QXl6zLTm8HpU"},"source":["#### `IMPORTIN LIBRARIES`"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1650258543867,"user":{"displayName":"Ganesh Shinde","userId":"04780742815385189197"},"user_tz":-330},"id":"hFs4rEpz8HpV"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\ganes\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pandas as pd\n","import nltk\n","import numpy as np\n","from nltk.corpus import stopwords\n","import re\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt')\n","from textblob import Word\n","import pickle\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.optimizers import SGD\n","from keras.models import Sequential\n","from keras.layers import Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout\n","from keras.metrics import Precision, Recall\n","from tensorflow.keras.optimizers import SGD\n","import keras.backend as K\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"cwJdfYrs8HpX"},"source":["### `IMPORTING DATASET`"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["ds=pd.read_csv(\"tweet_train.csv\",encoding=\"ISO-8859-1\",names=[\"label\", \"ids\", \"date\", \"flag\", \"user\", \"tweet\"])\n","ds=ds.drop([\"ids\",\"date\",\"flag\",\"user\"],axis=1)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["positive=ds[ds[\"label\"]==0][:1000]\n","neagtive=ds[ds[\"label\"]==4][:1000]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   label   1000 non-null   int64 \n"," 1   tweet   1000 non-null   object\n","dtypes: int64(1), object(1)\n","memory usage: 23.4+ KB\n","\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1000 entries, 800000 to 800999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   label   1000 non-null   int64 \n"," 1   tweet   1000 non-null   object\n","dtypes: int64(1), object(1)\n","memory usage: 23.4+ KB\n"]}],"source":["positive.info()\n","print()\n","neagtive.info()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>is upset that he can't update his Facebook by ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>@Kenichan I dived many times for the ball. Man...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>my whole body feels itchy and like its on fire</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>@nationwideclass no, it's not behaving at all....</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>0</td>\n","      <td>@dkoenigs thanks man.  I'm so very grateful.  ...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>0</td>\n","      <td>@t_wolfe  i miss u too. i'm totally comin back...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>0</td>\n","      <td>@sniffinglue ohhh. I love it. ps I'm sad we di...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>0</td>\n","      <td>And somehow I still end up in this place</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>0</td>\n","      <td>@kisluvkis oh that is very sad, poor boy.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 2 columns</p>\n","</div>"],"text/plain":["     label                                              tweet\n","0        0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n","1        0  is upset that he can't update his Facebook by ...\n","2        0  @Kenichan I dived many times for the ball. Man...\n","3        0    my whole body feels itchy and like its on fire \n","4        0  @nationwideclass no, it's not behaving at all....\n","..     ...                                                ...\n","995      0  @dkoenigs thanks man.  I'm so very grateful.  ...\n","996      0  @t_wolfe  i miss u too. i'm totally comin back...\n","997      0  @sniffinglue ohhh. I love it. ps I'm sad we di...\n","998      0          And somehow I still end up in this place \n","999      0         @kisluvkis oh that is very sad, poor boy. \n","\n","[1000 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["positive"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800000</th>\n","      <td>1</td>\n","      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n","    </tr>\n","    <tr>\n","      <th>800001</th>\n","      <td>1</td>\n","      <td>im meeting up with one of my besties tonight! ...</td>\n","    </tr>\n","    <tr>\n","      <th>800002</th>\n","      <td>1</td>\n","      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n","    </tr>\n","    <tr>\n","      <th>800003</th>\n","      <td>1</td>\n","      <td>Being sick can be really cheap when it hurts t...</td>\n","    </tr>\n","    <tr>\n","      <th>800004</th>\n","      <td>1</td>\n","      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>800995</th>\n","      <td>1</td>\n","      <td>I have this strange desire to go to confession...</td>\n","    </tr>\n","    <tr>\n","      <th>800996</th>\n","      <td>1</td>\n","      <td>@i_reporter answer sent in dm. try it</td>\n","    </tr>\n","    <tr>\n","      <th>800997</th>\n","      <td>1</td>\n","      <td>@brooklynunion cuz ur 3pm is my 9am and Id be ...</td>\n","    </tr>\n","    <tr>\n","      <th>800998</th>\n","      <td>1</td>\n","      <td>@littrellfans Its all good. Just figured you w...</td>\n","    </tr>\n","    <tr>\n","      <th>800999</th>\n","      <td>1</td>\n","      <td>@nicolerichie Yea I remember it</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 2 columns</p>\n","</div>"],"text/plain":["        label                                              tweet\n","800000      1       I LOVE @Health4UandPets u guys r the best!! \n","800001      1  im meeting up with one of my besties tonight! ...\n","800002      1  @DaRealSunisaKim Thanks for the Twitter add, S...\n","800003      1  Being sick can be really cheap when it hurts t...\n","800004      1    @LovesBrooklyn2 he has that effect on everyone \n","...       ...                                                ...\n","800995      1  I have this strange desire to go to confession...\n","800996      1             @i_reporter answer sent in dm. try it \n","800997      1  @brooklynunion cuz ur 3pm is my 9am and Id be ...\n","800998      1  @littrellfans Its all good. Just figured you w...\n","800999      1                   @nicolerichie Yea I remember it \n","\n","[1000 rows x 2 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["neagtive[\"label\"]=neagtive[\"label\"].apply(lambda x:1)\n","neagtive"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800010</th>\n","      <td>1</td>\n","      <td>crazy day of school. there for 10 hours straii...</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>0</td>\n","      <td>getting sick  time for some hot tea, studying,...</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>0</td>\n","      <td>I wish I was better at writing. It's taking me...</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0</td>\n","      <td>@maxime68 @megelder But! I'm useless if I don'...</td>\n","    </tr>\n","    <tr>\n","      <th>800760</th>\n","      <td>1</td>\n","      <td>@deepbluesealove I was never an early morning ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>800604</th>\n","      <td>1</td>\n","      <td>@EmilyCello Nessun realmente! ... I guess &amp;quo...</td>\n","    </tr>\n","    <tr>\n","      <th>800903</th>\n","      <td>1</td>\n","      <td>@RepeaterBand I missed the show last Friday! I...</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>0</td>\n","      <td>@chriscantore congrats! I'm totally jealous! o...</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>0</td>\n","      <td>@ginayates Sorry to hear about Maggie.    Thou...</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>0</td>\n","      <td>@ddlovato Do you hate us?? Please don't</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 2 columns</p>\n","</div>"],"text/plain":["        label                                              tweet\n","800010      1  crazy day of school. there for 10 hours straii...\n","156         0  getting sick  time for some hot tea, studying,...\n","326         0  I wish I was better at writing. It's taking me...\n","427         0  @maxime68 @megelder But! I'm useless if I don'...\n","800760      1  @deepbluesealove I was never an early morning ...\n","...       ...                                                ...\n","800604      1  @EmilyCello Nessun realmente! ... I guess &quo...\n","800903      1  @RepeaterBand I missed the show last Friday! I...\n","265         0  @chriscantore congrats! I'm totally jealous! o...\n","551         0  @ginayates Sorry to hear about Maggie.    Thou...\n","573         0           @ddlovato Do you hate us?? Please don't \n","\n","[2000 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["dataset=pd.concat([positive,neagtive])\n","dataset=dataset.sample(frac=1)\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"Cc_iEAkH8HpY"},"source":["### `PRE-PROCESSING`"]},{"cell_type":"markdown","metadata":{"id":"uw8hfhNc9JmN"},"source":["##### `PRE PROCESSING VARIABLE SETTING`"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n","dataset['tweet'] = dataset['tweet'].apply(lambda x: re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\",' ',x))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800010</th>\n","      <td>1</td>\n","      <td>crazy day of school there for 10 hours straiii...</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>0</td>\n","      <td>getting sick time for some hot tea studying an...</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>0</td>\n","      <td>I wish I was better at writing It s taking me ...</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0</td>\n","      <td>megelder But I m useless if I don t sleep It...</td>\n","    </tr>\n","    <tr>\n","      <th>800760</th>\n","      <td>1</td>\n","      <td>I was never an early morning person so I rea...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>800604</th>\n","      <td>1</td>\n","      <td>Nessun realmente I guess quot No Davvvero qu...</td>\n","    </tr>\n","    <tr>\n","      <th>800903</th>\n","      <td>1</td>\n","      <td>I missed the show last Friday I was so bumme...</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>0</td>\n","      <td>congrats I m totally jealous only wish my XM...</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>0</td>\n","      <td>Sorry to hear about Maggie Thoughts to your ...</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>0</td>\n","      <td>Do you hate us Please don t</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 2 columns</p>\n","</div>"],"text/plain":["        label                                              tweet\n","800010      1  crazy day of school there for 10 hours straiii...\n","156         0  getting sick time for some hot tea studying an...\n","326         0  I wish I was better at writing It s taking me ...\n","427         0    megelder But I m useless if I don t sleep It...\n","800760      1    I was never an early morning person so I rea...\n","...       ...                                                ...\n","800604      1    Nessun realmente I guess quot No Davvvero qu...\n","800903      1    I missed the show last Friday I was so bumme...\n","265         0    congrats I m totally jealous only wish my XM...\n","551         0    Sorry to hear about Maggie Thoughts to your ...\n","573         0                       Do you hate us Please don t \n","\n","[2000 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800010</th>\n","      <td>1</td>\n","      <td>crazy day school 10 hours straiiight watch hil...</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>0</td>\n","      <td>getting sick time hot tea studying sleeeep</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>0</td>\n","      <td>I wish I better writing It taking long write p...</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0</td>\n","      <td>megelder But I useless I sleep It fair I want ...</td>\n","    </tr>\n","    <tr>\n","      <th>800760</th>\n","      <td>1</td>\n","      <td>I never early morning person I really didnt an...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>800604</th>\n","      <td>1</td>\n","      <td>Nessun realmente I guess quot No Davvvero quot...</td>\n","    </tr>\n","    <tr>\n","      <th>800903</th>\n","      <td>1</td>\n","      <td>I missed show last Friday I bummed But I excit...</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>0</td>\n","      <td>congrats I totally jealous wish XM working</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>0</td>\n","      <td>Sorry hear Maggie Thoughts mum</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>0</td>\n","      <td>Do hate us Please</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 2 columns</p>\n","</div>"],"text/plain":["        label                                              tweet\n","800010      1  crazy day school 10 hours straiiight watch hil...\n","156         0         getting sick time hot tea studying sleeeep\n","326         0  I wish I better writing It taking long write p...\n","427         0  megelder But I useless I sleep It fair I want ...\n","800760      1  I never early morning person I really didnt an...\n","...       ...                                                ...\n","800604      1  Nessun realmente I guess quot No Davvvero quot...\n","800903      1  I missed show last Friday I bummed But I excit...\n","265         0         congrats I totally jealous wish XM working\n","551         0                     Sorry hear Maggie Thoughts mum\n","573         0                                  Do hate us Please\n","\n","[2000 rows x 2 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["dataset[\"tweet\"]=dataset[\"tweet\"].apply(lambda x: \" \".join([w for w in x.split() if w not in stopwords.words(\"english\")]))\n","dataset"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800010</th>\n","      <td>1</td>\n","      <td>crazy day school 10 hour straiiight watch hill...</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>0</td>\n","      <td>getting sick time hot tea studying sleeeep</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>0</td>\n","      <td>I wish I better writing It taking long write p...</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>0</td>\n","      <td>megelder But I useless I sleep It fair I want ...</td>\n","    </tr>\n","    <tr>\n","      <th>800760</th>\n","      <td>1</td>\n","      <td>I never early morning person I really didnt an...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>800604</th>\n","      <td>1</td>\n","      <td>Nessun realmente I guess quot No Davvvero quot...</td>\n","    </tr>\n","    <tr>\n","      <th>800903</th>\n","      <td>1</td>\n","      <td>I missed show last Friday I bummed But I excit...</td>\n","    </tr>\n","    <tr>\n","      <th>265</th>\n","      <td>0</td>\n","      <td>congrats I totally jealous wish XM working</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>0</td>\n","      <td>Sorry hear Maggie Thoughts mum</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>0</td>\n","      <td>Do hate u Please</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 2 columns</p>\n","</div>"],"text/plain":["        label                                              tweet\n","800010      1  crazy day school 10 hour straiiight watch hill...\n","156         0         getting sick time hot tea studying sleeeep\n","326         0  I wish I better writing It taking long write p...\n","427         0  megelder But I useless I sleep It fair I want ...\n","800760      1  I never early morning person I really didnt an...\n","...       ...                                                ...\n","800604      1  Nessun realmente I guess quot No Davvvero quot...\n","800903      1  I missed show last Friday I bummed But I excit...\n","265         0         congrats I totally jealous wish XM working\n","551         0                     Sorry hear Maggie Thoughts mum\n","573         0                                   Do hate u Please\n","\n","[2000 rows x 2 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Lemmatizing\n","\n","dataset['tweet']=dataset['tweet'].apply(lambda x:\" \".join([Word(word).lemmatize() for word in x.split()]))\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"y7kv2wdS8Hpa"},"source":["### `SPLITTING DATA FOR TRAINING AND TESTING`"]},{"cell_type":"markdown","metadata":{"id":"FpItdfR28Hpd"},"source":["#### `LSTM MODEL`"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before Tokenization & Padding \n"," Awww bummer You shoulda got David Carr Third Day D\n","After Tokenization & Padding \n"," [ 168    3   65  210   60 1724  169  330 1725  331  495   68  373 1726\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0]\n"]}],"source":["max_words = 2000\n","max_len=50\n","\n","def tokenize_pad_sequences(text):\n","    tokenizer = Tokenizer(num_words=max_words, lower=True, split=' ')\n","    tokenizer.fit_on_texts(text)\n","    X = tokenizer.texts_to_sequences(text)\n","    X = pad_sequences(X, padding='post', maxlen=max_len)\n","    return X, tokenizer\n","\n","print('Before Tokenization & Padding \\n', dataset['tweet'][0])\n","X, tokenizer = tokenize_pad_sequences(dataset['tweet'])\n","print('After Tokenization & Padding \\n', X[0])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["with open('tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ganes\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\ganes\\AppData\\Local\\Temp\\ipykernel_19776\\1203253035.py:13: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n","\n"]}],"source":["vocab_size = 2000\n","embedding_size = 32\n","epochs=20\n","learning_rate = 0.1\n","decay_rate = learning_rate / epochs\n","momentum = 0.8\n","\n","sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n","model= Sequential()\n","model.add(Embedding(vocab_size, embedding_size, input_length=max_len))\n","model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(32)))\n","model.add(Dropout(0.2))\n","model.add(Dense(2, activation='softmax'))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1600, 50) (1600, 2)\n","(400, 50) (400, 2)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","Y=pd.get_dummies(dataset[\"label\"]).values\n","X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n","print(X_train.shape,y_train.shape)\n","print(X_test.shape,y_test.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["model.compile(loss='binary_crossentropy', optimizer=sgd, \n","               metrics=['accuracy', Precision(), Recall()])\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["model.fit(X_train, y_train,\n","                      validation_data=(X_test, y_test),\n","                      batch_size=10, epochs=30, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["twt = ['he is the such a bad guy']\n","#vectorizing the tweet by the pre-fitted tokenizer instance\n","twt = tokenizer.texts_to_sequences(twt)\n","#padding the tweet to have exactly the same shape as `embedding_2` input\n","twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n","print(twt)\n","sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n","if(np.argmax(sentiment) == 0):\n","    print(\"negative\")\n","elif (np.argmax(sentiment) == 1):\n","    print(\"positive\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.evaluate(X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model.save(\"lstm_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ml.ipynb","provenance":[]},"interpreter":{"hash":"9914e116a5374b2bff9620cffda55a18bf7ad1aca0b02877c92a777ba6978604"},"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
